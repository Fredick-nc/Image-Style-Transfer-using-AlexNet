{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60279720",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85a3544c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import imageio\n",
    "#import cv2\n",
    "from six.moves import urllib\n",
    "import random\n",
    "from PIL import Image, ImageOps\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import torch\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#绘图显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fee27fe",
   "metadata": {},
   "source": [
    "由于tensorflow2.0版本不兼容很多函数，这里启用version1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2425e973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/niecheng/miniforge3/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:111: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9d4e14",
   "metadata": {},
   "source": [
    "# Other Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994c04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义预训练模型下载函数，将预训练模型从imagenet上下载到本地文件中\n",
    "def Pre_Model_Download(download_link, file_name, expected_bytes):\n",
    "    if os.path.exists(file_name):\n",
    "        print(\"模型已经下载，模型就绪\")\n",
    "        return\n",
    "    print(\"正在下载预训练的神经网络\")\n",
    "    #将URL表示的网络对象复制到本地文件，返回值为一个元组（filename，header）\n",
    "    file_name, _ = urllib.request.urlretrieve(download_link, file_name)  #参数指定下载url以及保存到本地的路径\n",
    "    #函数的返回是一个os.stat_result对象，用于给出一个文件或文件描述符（file descriptor）的各种状态信息\n",
    "    file_stat = os.stat(file_name)\n",
    "    if file_stat.st_size == expected_bytes:\n",
    "        print('成功下载预训练的神经网络模型', file_name)\n",
    "    else:\n",
    "        raise Exception('文件：' + file_name +' 可能被占用，可以到网站上进行下载')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6149378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义初始化图片函数，主要用于将输入的图片修改为同样大小，神经网络可以接受的大小\n",
    "def Resize_Image(img_path, height, width, save=True):\n",
    "    image = Image.open(img_path)     #打开一个图片\n",
    "    image = ImageOps.fit(image, (width, height), Image.ANTIALIAS)  #返回一个指定大小的裁剪过的图像，过滤器为ANTIALIAS\n",
    "    if save:\n",
    "        image_dirs = img_path.split('/')\n",
    "        image_dirs[-1] = 'resized_' + image_dirs[-1]\n",
    "        out_path = '/'.join(image_dirs)\n",
    "        if not os.path.exists(out_path):\n",
    "            image.save(out_path)\n",
    "    image = np.asarray(image, np.float32)\n",
    "    return np.expand_dims(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09087050",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义生成白噪声图片函数：未经学习的图像为白噪声形式，在神经网络不断训练后成为风格和内容图像合成的图像\n",
    "def Noise_Image(content_image, height, width, noise_ratio=0.6):   #初始化白噪声比率为0.6\n",
    "    #从一个均匀分布[-20,20)中随机采样，size为输入的图片，返回的形式与输入一致\n",
    "    noise_image = np.random.uniform(-20, 20, (1, height, width, 3)).astype(np.float32) \n",
    "    return noise_image * noise_ratio + content_image * (1 - noise_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab865c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义图片保存函数，用于保存最终的输出结果\n",
    "def Save_Image(path, image):\n",
    "    image = image[0] \n",
    "    #利用np.clip截取数组中小于0或者大于255的部分，并使得被截取部分等于固定值。\n",
    "    image = np.clip(image, 0, 255).astype('uint8')\n",
    "    imageio.imwrite(path, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0aadf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建文件夹\n",
    "def make_dir(path):\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662f4ccb",
   "metadata": {},
   "source": [
    "## Image Processing："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc5c48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义绘制内容图像、风格图像以及合成图像的函数，这里用于对比展示\n",
    "def plot_images(content_image, style_image, mixed_image):\n",
    "    #创建子图\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "\n",
    "    #调整垂直间隔\n",
    "    fig.subplots_adjust(hspace=0.1, wspace=0.1)\n",
    "\n",
    "    #使用插值法平滑像素\n",
    "    smooth = True\n",
    "    \n",
    "    #定义插值类型\n",
    "    if smooth:\n",
    "#        interpolation = 'sinc'\n",
    "        interpolation = 'bilinear'    #图像处理改进：对于图片的插值类型进行了改变，sinc函数内插变为双线性插值\n",
    "    else:\n",
    "        interpolation = 'nearest'\n",
    "\n",
    "    # 绘制内容图像；像素值被标准化至[0,1]中\n",
    "    ax = axes.flat[0]\n",
    "    ax.imshow(content_image / 255.0, interpolation = interpolation)\n",
    "    ax.set_xlabel(\"内容图像\")\n",
    "\n",
    "    # 绘制合成图像\n",
    "    ax = axes.flat[1]\n",
    "    ax.imshow(mixed_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"合成图像\")\n",
    "\n",
    "    # 绘制风格图像\n",
    "    ax = axes.flat[2]\n",
    "    ax.imshow(style_image / 255.0, interpolation=interpolation)\n",
    "    ax.set_xlabel(\"风格图像\")\n",
    "\n",
    "    #从图像中去掉刻度\n",
    "    for ax in axes.flat:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c68d67c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义图像加载函数\n",
    "def load_image(filename, max_size=None):\n",
    "    image = Image.open(filename)\n",
    "\n",
    "    if max_size is not None:\n",
    "        # 计算合适的缩放因子以确保最大的图像高度和宽度，两者保证一个比例\n",
    "        factor = max_size / np.max(image.size)\n",
    "    \n",
    "        # 缩放图像的长和宽\n",
    "        size = np.array(image.size) * factor\n",
    "\n",
    "        # 在缩放后，size变为浮点类型，而PIL要求输入为整数，这里进行数字类型转换\n",
    "        size = size.astype(int)\n",
    "\n",
    "        #重新改变图像的大小\n",
    "        image = image.resize(size, Image.LANCZOS)\n",
    "\n",
    "    # 转为numpy浮点类型矩阵\n",
    "    return np.float32(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a0b9ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义权重函数，用于配制内容图像与风格图像融入到合成图像的比例\n",
    "def Set_Weights(trained_layers, layer_idx, expected_layer_name):\n",
    "    \"\"\" 返回已经训练的权重和偏置\"\"\"\n",
    "    W = trained_layers[0][layer_idx][0][0][2][0][0]\n",
    "    b = trained_layers[0][layer_idx][0][0][2][0][1]\n",
    "    layer_name = trained_layers[0][layer_idx][0][0][0][0]\n",
    "    \n",
    "    assert layer_name == expected_layer_name\n",
    "    \n",
    "    b = b.reshape(b.size)\n",
    "        \n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ea5940",
   "metadata": {},
   "source": [
    "## Add new activation function into layers："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be08dd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置卷积层搭建函数\n",
    "#设置的参数分别为训练过的层，预训练的层，层索引，层名称，图像高度，图像宽度，组别（内容/风格），填充设为same表示输入和输出图像的大小相同\n",
    "def Conv2d(trained_layers, prev_layer, layer_idx, layer_name, s_h, s_w, group, padding='SAME'):\n",
    "\n",
    "    with tf.compat.v1.variable_scope(layer_name) as scope:\n",
    "        w, b = Set_Weights(trained_layers, layer_idx, layer_name)  #对训练的层进行权重配置\n",
    "        w = tf.constant(w, name='weights')  #创建常量权重\n",
    "        b = tf.constant(b, name='bias')     #创建常量偏置\n",
    "        \n",
    "        convolve = lambda inputs, weigths: tf.nn.conv2d(inputs, weigths, [1, s_h, s_w, 1], padding=padding)\n",
    "    \n",
    "        if group==1:\n",
    "            conv2d = convolve(prev_layer, w)\n",
    "        else:\n",
    "            # 将输入、权重和卷积层分开\n",
    "            input_groups = tf.split(prev_layer, group, 3)\n",
    "            kernel_groups = tf.split(w, group, 3)\n",
    "            output_groups = [tf.nn.conv2d(i, k, [1, s_h, s_w, 1], padding=padding)\n",
    "                             for i, k in zip(input_groups, kernel_groups)]\n",
    "            conv2d = tf.concat(output_groups, 3)\n",
    "            \n",
    "        conv_lin = tf.reshape(tf.nn.bias_add(conv2d, b), [-1] + conv2d.get_shape().as_list()[1:], name='lin')\n",
    "#         conv_relu = tf.nn.relu(conv_lin, name='relu')  通常情况下，习惯使用ReLU函数\n",
    "        conv_elu = tf.nn.elu(conv_lin, name='elu')   #创新点一：使用elu函数减小偏置带来的影响\n",
    "\n",
    "        return conv_elu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63b2cff-2743-4c58-8b2d-563e9879b875",
   "metadata": {},
   "source": [
    "### ELU activation function："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496dd7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [-5.         -4.28571429 -3.57142857 -2.85714286 -2.14285714 -1.42857143\n",
      " -0.71428571  0.          0.71428571  1.42857143  2.14285714  2.85714286\n",
      "  3.57142857  4.28571429  5.        ]\n",
      "Output: [-0.99326205 -0.98623621 -0.97188434 -0.94256738 -0.88268083 -0.76034896\n",
      " -0.51045834  0.          0.71428571  1.42857143  2.14285714  2.85714286\n",
      "  3.57142857  4.28571429  5.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-12 20:48:14.640148: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.linspace(-5, 5, 15) \n",
    "  \n",
    "b = tf.nn.elu(a, name ='elu') \n",
    "  \n",
    "with tf.Session() as sess:\n",
    "    print('Input:', a) \n",
    "    print('Output:', sess.run(b)) \n",
    "    plt.plot(a, sess.run(b), color = 'red', marker = \"o\")  \n",
    "    plt.title(\"ELU激活函数曲线图\")  \n",
    "    plt.xlabel(\"X\")  \n",
    "    plt.ylabel(\"Y\")  \n",
    "  \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4646268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义池化层函数\n",
    "# 使用最大池化层效果最佳，取feature maps中最重要的特征\n",
    "def MaxPool(prev_layer, layer_name):\n",
    "    return tf.nn.max_pool(prev_layer, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name=layer_name)\n",
    "\n",
    "def AvgPool(prev_layer, layer_name):\n",
    "    return tf.nn.avg_pool(prev_layer, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name=layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d849455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义学习率函数\n",
    "def Learning_rate(prev_layer, layer_name):  \n",
    "    #使用了LRN局部响应归一化\n",
    "    return tf.nn.local_response_normalization(prev_layer, depth_radius=2, alpha=2e-05, beta=0.75,bias=1.0,name=layer_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9c34e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载文件中下载的预训练的网络\n",
    "def load_net_from_file(path, input_image):\n",
    "\n",
    "    net = scipy.io.loadmat(path)\n",
    "    trained_layers = net['layers']\n",
    "   \n",
    "    graph = {} \n",
    "    graph['conv1']  = Conv2d(trained_layers , input_image, 0, 'conv1', s_h=4, s_w=4, group=1)\n",
    "    graph['norm1']  = Learning_rate(graph['conv1'], 'norm1')\n",
    "    graph['pool1']  = MaxPool(graph['norm1'], 'pool1')\n",
    "    \n",
    "    graph['conv2']  = Conv2d(trained_layers, graph['pool1'], 4, 'conv2', s_h=1, s_w=1, group=2)\n",
    "    graph['norm2']  = Learning_rate(graph['conv2'], 'norm2')\n",
    "    graph['pool2']  = MaxPool(graph['norm2'], 'pool2')\n",
    "    \n",
    "    graph['conv3']  = Conv2d(trained_layers, graph['pool2'], 8, 'conv3', s_h=1, s_w=1, group=1)\n",
    "    graph['conv4']  = Conv2d(trained_layers, graph['conv3'], 10, 'conv4', s_h=1, s_w=1, group=2)\n",
    "    graph['conv5']  = Conv2d(trained_layers, graph['conv4'], 12, 'conv5', s_h=1, s_w=1, group=2)    \n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd318393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#用于计算内容图像与合成图像之间的特征损失\n",
    "def Content_Loss(p, f):\n",
    "    return tf.reduce_sum((f - p) ** 2) / (4.0 * p.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f8de9e-f1d3-4977-8784-f2ba251b365d",
   "metadata": {},
   "source": [
    "### Fix Gram matrix by adding shifted value for eliminating too many zero terms in Gram matrix to lower sparsity："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca619e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义Gram矩阵，用于计算风格特征损失\n",
    "def Gram_Matrix(F, N, M):\n",
    "\n",
    "    F = tf.reshape(F, (M, N))  #输入的F为tensor形式\n",
    "    return tf.matmul(tf.transpose(F - 1), F - 1)   #这里使用matmul专门用于tensor的点乘\n",
    "    #根据论文中所述：s = -1为最佳shifted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80761aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算某一网络层的风格损失，a为真实图像的特征代表，g为生成图像的特征代表\n",
    "def Single_Style_Loss(a, g):\n",
    "\n",
    "    N = a.shape[3] # 过滤器个数\n",
    "    M = a.shape[1] * a.shape[2] # feature map中高和宽之积\n",
    "    A = Gram_Matrix(a, N, M)\n",
    "    G = Gram_Matrix(g, N, M)\n",
    "    \n",
    "    return tf.reduce_sum((G - A) ** 2 / ((2 * N * M) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c73946e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义总的风格损失函数\n",
    "def Style_Loss(A, model):\n",
    "    \n",
    "    n_layers = len(STYLE_LAYERS)\n",
    "    E = [Single_Style_Loss(A[i], model[STYLE_LAYERS[i]]) for i in range(n_layers)]\n",
    "    \n",
    "    return sum([W[i] * E[i] for i in range(n_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2676b740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算总损失（内容损失 + 风格损失）\n",
    "def Total_Loss(model, input_image, content_image, style_image):\n",
    "    with tf.compat.v1.variable_scope('loss') as scope:\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            sess.run(input_image.assign(content_image)) # 指定内容图像至输入变量\n",
    "            p = sess.run(model[CONTENT_LAYER])\n",
    "        content_loss = Content_Loss(p, model[CONTENT_LAYER])\n",
    "\n",
    "        with tf.compat.v1.Session() as sess:\n",
    "            sess.run(input_image.assign(style_image))\n",
    "            A = sess.run([model[layer_name] for layer_name in STYLE_LAYERS])                              \n",
    "        style_loss = Style_Loss(A, model)\n",
    "\n",
    "        total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n",
    "       \n",
    "    return content_loss, style_loss, total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a293472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对模型配置进行整体概览\n",
    "def Summary(model):\n",
    "    \n",
    "    with tf.name_scope('summaries'):\n",
    "        tf.summary.scalar('content loss', model['content_loss'])\n",
    "        tf.summary.scalar('style loss', model['style_loss'])\n",
    "        tf.summary.scalar('total loss', model['total_loss'])\n",
    "        tf.summary.histogram('histogram content loss', model['content_loss'])\n",
    "        tf.summary.histogram('histogram style loss', model['style_loss'])\n",
    "        tf.summary.histogram('histogram total loss', model['total_loss'])\n",
    "        return tf.compat.v1.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a901f67f",
   "metadata": {},
   "source": [
    "# Parameters setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9e61923",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Test_dataset_stylesplit/style1/000000001730.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m CONTENT_IMAGE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Test_dataset_stylesplit/style1/000000001730.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     20\u001b[0m STYLE_IMAGE_PATH \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Alexnet_Style_Transfer_results/style_input/Van_Gogh_starry_sky.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 23\u001b[0m img_original \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_IMAGE_PATH\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m#读取内容图像表示的二维矩阵\u001b[39;00m\n\u001b[1;32m     25\u001b[0m IMAGE_HEIGHT \u001b[38;5;241m=\u001b[39m img_original\u001b[38;5;241m.\u001b[39mheight  \u001b[38;5;66;03m#将生成图像的长和宽与原内容图像保持一致\u001b[39;00m\n\u001b[1;32m     26\u001b[0m IMAGE_WIDTH \u001b[38;5;241m=\u001b[39m img_original\u001b[38;5;241m.\u001b[39mwidth\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/PIL/Image.py:2953\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2950\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   2952\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 2953\u001b[0m     fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2954\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2956\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Test_dataset_stylesplit/style1/000000001730.jpg'"
     ]
    }
   ],
   "source": [
    "DOWNLOAD_LINK = 'http://www.vlfeat.org/matconvnet/models/imagenet-caffe-alex.mat'\n",
    "File_MODEL_PATH = 'imagenet-caffe-alex.mat'\n",
    "EXPECTED_BYTES = 228041398   \n",
    "\n",
    "MODEL_NET_NAME = './Alexnet_Style_Transfer_results/alexnet'   #根路径\n",
    "OUTPUT_PATH = MODEL_NET_NAME + '_outputs'            #合成图片输出路径\n",
    "CHECKPOINT_PATH = MODEL_NET_NAME + '_checkpoints'    #训练节点输出路径\n",
    "GRAPHS_PATH = MODEL_NET_NAME + '_graphs'            #网络输出路径\n",
    "\n",
    "#定义读取内容图像和风格图像的路径\n",
    "\n",
    "# mylist = os.listdir('./Test_dataset/')\n",
    "# root_path = './Test_dataset/'\n",
    "\n",
    "#random.seed(1)\n",
    "#CONTENT_IMAGE_PATH = root_path + random.choice(mylist) \n",
    "CONTENT_IMAGE_PATH = './Test_dataset_stylesplit/style1/000000001730.jpg'\n",
    "\n",
    "\n",
    "STYLE_IMAGE_PATH = './Alexnet_Style_Transfer_results/style_input/Van_Gogh_starry_sky.jpg'\n",
    "\n",
    "\n",
    "img_original = Image.open(CONTENT_IMAGE_PATH)  #读取内容图像表示的二维矩阵\n",
    "\n",
    "IMAGE_HEIGHT = img_original.height  #将生成图像的长和宽与原内容图像保持一致\n",
    "IMAGE_WIDTH = img_original.width\n",
    "\n",
    "CONTENT_WEIGHT = 0.01   #内容图像权重\n",
    "STYLE_WEIGHT = 1       #风格图像权重\n",
    "\n",
    "NOISE_RATIO = 0.6     #白噪声与原内容图像混合的比例\n",
    "\n",
    "ITERS = 200           #迭代次数\n",
    "LR = 2.0              #固定学习率\n",
    "\n",
    "\n",
    "# 指定用于风格特征的网络层\n",
    "STYLE_LAYERS = ['conv1', 'conv3', 'conv4', 'conv5']\n",
    "#越深的层数指定更大的权重\n",
    "W = [0.1, 0.2, 0.3, 0.4] \n",
    "\n",
    "# 指定用于内容特征的网络层\n",
    "CONTENT_LAYER = 'conv2'\n",
    "\n",
    "#这里的数组是RGB通道固定数值\n",
    "MEAN_PIXELS = np.array([123.68, 116.779, 103.939]).reshape((1,1,1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c633577",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d773d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型训练函数，输入参数为模型，生成图片以及初始化图片\n",
    "def train(model, generated_image, initial_image):\n",
    "    \"\"\" 模型训练 \"\"\"\n",
    "    skip_step = 1   #设置skip的目的是不需要展示所有的训练步骤，去间隔值进行展示\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        \n",
    "        saver = tf.compat.v1.train.Saver()  #用于保存、恢复变量或模型\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())  #在含有tf.Variable的环境下，进行初始化全局变量\n",
    "        writer = tf.compat.v1.summary.FileWriter(GRAPHS_PATH, sess.graph) #读取图片\n",
    "        \n",
    "        sess.run(generated_image.assign(initial_image))    #首先对生成图像分配初始化白噪声图像\n",
    "        ckpt = tf.train.get_checkpoint_state(os.path.dirname(CHECKPOINT_PATH))\n",
    "        if ckpt and ckpt.model_checkpoint_path:\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        initial_step = model['global_step'].eval()  #用于计算返回numpy结果\n",
    "        \n",
    "        start_time = time.time()   #设计一个训练模型的时间返回器\n",
    "        for index in range(initial_step, ITERS):\n",
    "            if index >= 5 and index < 20:\n",
    "                skip_step = 10\n",
    "            elif index >= 20:\n",
    "                skip_step = 20\n",
    "            \n",
    "            sess.run(model['optimizer'])\n",
    "            if (index + 1) % skip_step == 0:   #展示训练过程中的图片以及损失\n",
    "                gen_image, total_loss, summary = sess.run([generated_image, model['total_loss'], model['summary_op']])\n",
    "                gen_image = gen_image + MEAN_PIXELS\n",
    "                writer.add_summary(summary, global_step=index)\n",
    "                print('第 {} 步\\n  总和为: {:5.1f}'.format(index + 1, np.sum(gen_image)))\n",
    "                print('总损失为: {:5.1f}'.format(total_loss))\n",
    "                print('本次训练所用时长: {}'.format(time.time() - start_time))\n",
    "                start_time = time.time()\n",
    "\n",
    "                filename = OUTPUT_PATH + '/%d.png' % (index)   #保存生成的合成图像\n",
    "                \n",
    "                Save_Image(filename, gen_image)\n",
    "                \n",
    "                #加载图像并合并以更好地展示对比\n",
    "                c_image = load_image(CONTENT_IMAGE_PATH,max_size=IMAGE_HEIGHT)\n",
    "                s_image = load_image(STYLE_IMAGE_PATH,max_size=IMAGE_HEIGHT)\n",
    "                g_image = load_image(filename,max_size=IMAGE_HEIGHT)\n",
    "                plot_images(content_image=c_image,style_image=s_image,mixed_image=g_image)\n",
    "                \n",
    "                if (index + 1) % 20 == 0:\n",
    "                    saver.save(sess, CHECKPOINT_PATH + '/style_transfer', index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f0dccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    with tf.compat.v1.variable_scope('input') as scope:\n",
    "        # 使用variable而不是placeholder，让生成图像结合内容图像和风格图像\n",
    "        input_image = tf.Variable(np.zeros([1, IMAGE_HEIGHT, IMAGE_WIDTH, 3]), dtype=tf.float32)\n",
    "        # 加载预训练模型\n",
    "        Pre_Model_Download(DOWNLOAD_LINK, File_MODEL_PATH, EXPECTED_BYTES)\n",
    "        \n",
    "    make_dir(CHECKPOINT_PATH)\n",
    "    make_dir(OUTPUT_PATH)\n",
    "    \n",
    "    model = load_net_from_file(File_MODEL_PATH, input_image)\n",
    "    model['global_step'] = tf.Variable(0, dtype=tf.int32, trainable=False, name='global_step')\n",
    "\n",
    "    #重新调整内容图像以及风格图像的大小\n",
    "    content_image = Resize_Image(CONTENT_IMAGE_PATH, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    content_image = content_image - MEAN_PIXELS\n",
    "    \n",
    "  \n",
    "    style_image = Resize_Image(STYLE_IMAGE_PATH, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    style_image = style_image - MEAN_PIXELS\n",
    "\n",
    "    #计算三个损失\n",
    "    model['content_loss'], model['style_loss'], model['total_loss'] = Total_Loss(model, input_image, content_image, style_image)\n",
    "    \n",
    "    #迭代优化，选择Adam优化器线性优化\n",
    "    model['optimizer'] = tf.compat.v1.train.AdamOptimizer(LR).minimize(model['total_loss'], global_step=model['global_step'])\n",
    "    \n",
    "    model['summary_op'] = Summary(model)\n",
    "\n",
    "    initial_image = Noise_Image(content_image, IMAGE_HEIGHT, IMAGE_WIDTH, NOISE_RATIO)\n",
    "    \n",
    "    train(model, input_image, initial_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bb3455c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已经下载，模型就绪\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "elu() got an unexpected keyword argument 'alpha'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-586598249d8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-123-d73c5d05f0ed>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmake_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mOUTPUT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_net_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFile_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'global_step'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'global_step'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-114-8fd288c47400>\u001b[0m in \u001b[0;36mload_net_from_file\u001b[0;34m(path, input_image)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrained_layers\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'conv1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_h\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms_w\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'norm1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mLearning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conv1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'norm1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pool1'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mMaxPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'norm1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pool1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-55ab16e442cb>\u001b[0m in \u001b[0;36mConv2d\u001b[0;34m(trained_layers, prev_layer, layer_idx, layer_name, s_h, s_w, group, padding)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mconv_lin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mconv2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         conv_relu = tf.nn.relu(conv_lin, name='relu')  通常情况下，习惯使用ReLU函数\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mconv_elu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_lin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'elu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m#创新点一：使用elu函数减小偏置带来的影响\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mconv_elu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: elu() got an unexpected keyword argument 'alpha'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "main()\n",
    "    \n",
    "end_time = time.time()\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "\n",
    "print(\"模型训练总时长为: %s\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d1f26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
