{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7a37bea",
   "metadata": {},
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa08985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import vgg19\n",
    "from torchvision import transforms as tf\n",
    "import time \n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d48c8a",
   "metadata": {},
   "source": [
    "## Parameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e512fb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 1e3   # 内容损失权重\n",
    "β = 1e3  # 风格损失权重\n",
    "γ = 0\n",
    "EPOCH = 500 # 迭代次数\n",
    "Content_layer = 4\n",
    "closs, sloss = [0.],[0.]\n",
    "mse_loss = nn.MSELoss(reduction='mean') # 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38350cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像预处理\n",
    "transform = tf.Compose([ # 喂入网络\n",
    "                tf.Resize((512,512)),\n",
    "                tf.ToTensor(),\n",
    "                tf.Normalize([0.485, 0.456, 0.406], [1, 1, 1]),\n",
    "            ])\n",
    "decode = tf.Compose([  # 复原(transform逆操作)\n",
    "                tf.Normalize([-0.485,-0.456,-0.406], [1, 1, 1]),       \n",
    "                tf.Lambda(lambda x: x.clamp(0,1))\n",
    "            ])\n",
    "tensor2PIL = tf.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aa78b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = os.listdir('./Test_dataset')\n",
    "root_path = './Test_dataset/'\n",
    "\n",
    "\n",
    "style_img_path = './Alexnet_Style_Transfer_results/style_input/style.jpg'  # 风格图\n",
    "\n",
    "content_img_path =  root_path + mylist[1] # 内容图\n",
    "\n",
    "style_img = Image.open(style_img_path)\n",
    "content_img = Image.open(content_img_path)\n",
    "\n",
    "style_img = transform(style_img)\n",
    "content_img = transform(content_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e72d1c",
   "metadata": {},
   "source": [
    "# Content Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9c1512d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内容损失:\n",
    "class content_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(content_loss, self).__init__()\n",
    "\n",
    "    def forward(self, content, content_target):\n",
    "        c_loss = mse_loss(content, content_target)\n",
    "        return c_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6365a9",
   "metadata": {},
   "source": [
    "# Style Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6728c763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算格拉姆矩阵\n",
    "def gram_matrix(x):\n",
    "    # x = x.unsqueeze(0)\n",
    "    b, c, h, w = x.size()\n",
    "    F = x.view(b,c,h*w)\n",
    "    # torch.bmm计算两个矩阵的矩阵乘法，维度必须是(batches, w, h)\n",
    "    G = torch.bmm(F, F.transpose(1,2))/(h*w)\n",
    "    return G\n",
    "    \n",
    "    \n",
    "# 风格损失:\n",
    "class style_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(style_loss, self).__init__()\n",
    "\n",
    "    def forward(self, gram_styles, gram_targets):\n",
    "        s_loss = 0\n",
    "        for i in range(5):\n",
    "            # N = gram_styles[i].shape[-1]\n",
    "            # M = style_features[i].shape[-1]\n",
    "            s_loss += mse_loss(gram_styles[i],gram_targets[i])\n",
    "        return s_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3d665f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 平滑损失:\n",
    "class smooth_loss(nn.Module):\n",
    "     def __init__(self):\n",
    "        super(smooth_loss, self).__init__()\n",
    "    \n",
    "     def forward(self, x):\n",
    "        smoothloss = torch.mean(torch.abs(x[:, :, 1:, :]-x[:, :, :-1, :])) + torch.mean(torch.abs(x[:, :, :, 1:]-x[:, :, :, :-1]))\n",
    "        return smoothloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "307bdc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 总损失:\n",
    "class total_loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(total_loss, self).__init__()\n",
    "\n",
    "    def forward(self, content, content_target, gram_styles, gram_targets, image, α, β):\n",
    "        closs = content_loss()\n",
    "        sloss = style_loss()\n",
    "        smooth = smooth_loss()\n",
    "        c = closs(content, content_target)\n",
    "        s = sloss(gram_styles, gram_targets)\n",
    "        t = α * c + β * s # + γ * smooth(image)\n",
    "        return t, α * c, β * s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda5c64",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "36621181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取网络某层的输出\n",
    "def get_features(module, x, y):\n",
    "    features.append(y)\n",
    "    \n",
    "    \n",
    "# 只需要卷积层\n",
    "VGG = vgg19(pretrained=True).features\n",
    "\n",
    "for i, layer in enumerate(VGG):\n",
    "    # 获取forward过程中网络特定层的输出, 21层用作计算内容损失, 其余用作计算风格损失\n",
    "    if i in [0,5,10,19,21,28]:\n",
    "        VGG[i].register_forward_hook(get_features) \n",
    "    # 将网络中的最大池化全部替换为平均池化，论文中表示这样生成效果更好\n",
    "    elif isinstance(layer, nn.MaxPool2d):\n",
    "        VGG[i] = nn.AvgPool2d(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "27e20782",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG.eval()\n",
    "# 由于优化的是生成图，因此冻结网络的参数\n",
    "for p in VGG.parameters():\n",
    "    p.requires_grad = False\n",
    "\n",
    "# 内容损失需要参考的网络输出层\n",
    "features = []  # features用来保存网络中间层输出\n",
    "VGG(content_img.unsqueeze(0))\n",
    "content_target = features[Content_layer].detach() \n",
    "# 风格损失需要参考的网络输出层\n",
    "features = []\n",
    "VGG(style_img.unsqueeze(0))\n",
    "s_targets = features[:4] + features[5:] \n",
    "# 计算风格图的格拉姆矩阵:\n",
    "gram_targets = [gram_matrix(i).detach() for i in s_targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6703377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 优化图像就是原图\n",
    "image = content_img.clone().unsqueeze(0)      \n",
    "# 优化图像是随机噪声\n",
    "# image = torch.randn(1,3,512,512).to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "abacc5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 牛顿二阶优化法(学习率为1.1)\n",
    "optimizer = optim.LBFGS([image.requires_grad_()], lr=1.1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0effa547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Style loss: 34.88028336 Content loss: 7.77232075\n",
      "Step 50: Style loss: 16.22610283 Content loss: 3.53334665\n",
      "Step 100: Style loss: 16.03314209 Content loss: 3.42153072\n",
      "Step 150: Style loss: 15.97256947 Content loss: 3.38263631\n",
      "Step 200: Style loss: 15.94287491 Content loss: 3.36089635\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "for step in range(EPOCH):\n",
    "\n",
    "    features = []\n",
    "    # LBFGS需要重复多次计算函数，因此需要传入一个闭包去允许它们重新计算你的模型。这个闭包应当清空梯度，计算损失，然后返回\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        VGG(image)\n",
    "        t_features = features[-6:]\n",
    "        # 内容层\n",
    "        content = t_features[Content_layer]  \n",
    "        # 风格层  \n",
    "        style_features = t_features[:4] + t_features[5:] \n",
    "        t_features = []\n",
    "        # 计算风格层的格拉姆矩阵\n",
    "        gram_styles = [gram_matrix(i) for i in style_features]  \n",
    "\n",
    "        # 计算损失\n",
    "        loss = total_loss()\n",
    "        tloss, closs[0], sloss[0] = loss(content, content_target, gram_styles, gram_targets, image, α, β)\n",
    "        tloss.backward()\n",
    "        return tloss\n",
    "\n",
    "    optimizer.step(closure)\n",
    "    \n",
    "\n",
    "    \n",
    "    # 保存生成图像\n",
    "    if step % 50 == 0:\n",
    "        print('Step {}: Style loss: {:.8f} Content loss: {:.8f}'.format(step, sloss[0], closs[0]))\n",
    "        temp = decode(image[0].cpu().detach())\n",
    "        temp = tensor2PIL(temp)\n",
    "        temp = np.array(temp)\n",
    "        plt.imsave('./Gatys_Style_Transfer_results/{}_styled.jpg'.format(mylist[1]),temp)\n",
    "        \n",
    "        \n",
    "end_time = time.time()\n",
    "elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(end_time - start_time))\n",
    "\n",
    "print(\"模型训练总时长为: %s\" % elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2f29777",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list = []\n",
    "time_list.append(elapsed_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a289c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
